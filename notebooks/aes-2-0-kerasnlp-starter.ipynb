{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":6063,"sourceType":"modelInstanceVersion","modelInstanceId":4684},{"sourceId":6065,"sourceType":"modelInstanceVersion","modelInstanceId":4686}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":145.342814,"end_time":"2024-04-04T17:28:39.209886","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-04T17:26:13.867072","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/awsaf49/aes-2-0-kerasnlp-starter?scriptVersionId=173101436\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\nThis starter notebook is provided by the Keras team.</center>","metadata":{"papermill":{"duration":0.013391,"end_time":"2024-04-04T17:26:16.758201","exception":false,"start_time":"2024-04-04T17:26:16.74481","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Automated Essay Scoring 2.0 with [KerasNLP](https://github.com/keras-team/keras-nlp) and [Keras](https://github.com/keras-team/keras)\n\n<div align=\"center\">\n    <img src=\"https://i.ibb.co/BrZf1MC/AESv2.jpg\">\n</div>\n\nIn this competition, our aim is to develop an AI model that can score student essays. This competition is actually an updated version of an old one that took place over a decade ago. In this version, we aim to improve upon essay scoring algorithms to enhance student learning outcomes. This notebook will guide you through the process of fine-tuning the **DebertaV3** model using **Ordinal Regression/Classification** to score student essays using KerasNLP.\n\n**Did you know**: This notebook is backend-agnostic, which means it supports TensorFlow, PyTorch, and JAX backends. However, the best performance can be achieved with `JAX`. KerasNLP and Keras enable the choice of the preferred backend. Explore further details on [Keras](https://keras.io/keras_3/).\n\n**Note**: For a deeper understanding of KerasNLP, refer to the [KerasNLP guides](https://keras.io/keras_nlp/).","metadata":{"papermill":{"duration":0.012811,"end_time":"2024-04-04T17:26:16.784578","exception":false,"start_time":"2024-04-04T17:26:16.771767","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# üìö | Import Libraries ","metadata":{"papermill":{"duration":0.012617,"end_time":"2024-04-04T17:26:16.810071","exception":false,"start_time":"2024-04-04T17:26:16.797454","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # \"jax\" or \"tensorflow\" or \"torch\" \n\nimport keras_nlp\nimport keras\nimport keras.backend as K\nimport tensorflow as tf\n\nimport numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\ncmap = mpl.cm.get_cmap('coolwarm')","metadata":{"_kg_hide-output":true,"papermill":{"duration":14.675271,"end_time":"2024-04-04T17:26:31.499426","exception":false,"start_time":"2024-04-04T17:26:16.824155","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:04.761534Z","iopub.execute_input":"2024-04-21T03:44:04.761964Z","iopub.status.idle":"2024-04-21T03:44:18.465886Z","shell.execute_reply.started":"2024-04-21T03:44:04.761924Z","shell.execute_reply":"2024-04-21T03:44:18.465004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Library Version","metadata":{"papermill":{"duration":0.016252,"end_time":"2024-04-04T17:26:31.537189","exception":false,"start_time":"2024-04-04T17:26:31.520937","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"TensorFlow:\", tf.__version__)\nprint(\"Keras:\", keras.__version__)\nprint(\"KerasNLP:\", keras_nlp.__version__)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.022091,"end_time":"2024-04-04T17:26:31.57546","exception":false,"start_time":"2024-04-04T17:26:31.553369","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:18.467938Z","iopub.execute_input":"2024-04-21T03:44:18.468488Z","iopub.status.idle":"2024-04-21T03:44:18.473672Z","shell.execute_reply.started":"2024-04-21T03:44:18.468459Z","shell.execute_reply":"2024-04-21T03:44:18.472791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ‚öôÔ∏è | Configuration","metadata":{"papermill":{"duration":0.012715,"end_time":"2024-04-04T17:26:31.601454","exception":false,"start_time":"2024-04-04T17:26:31.588739","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CFG:\n    seed = 42  # Random seed\n    preset = \"deberta_v3_extra_small_en\" # Name of pretrained models\n    sequence_length = 512  # Input sequence length\n    epochs = 5 # Training epochs\n    batch_size = 32  # Batch size\n    scheduler = 'cosine'  # Learning rate scheduler","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.022094,"end_time":"2024-04-04T17:26:31.636464","exception":false,"start_time":"2024-04-04T17:26:31.61437","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:18.474643Z","iopub.execute_input":"2024-04-21T03:44:18.474918Z","iopub.status.idle":"2024-04-21T03:44:18.498288Z","shell.execute_reply.started":"2024-04-21T03:44:18.474894Z","shell.execute_reply":"2024-04-21T03:44:18.497397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ‚ôªÔ∏è | Reproducibility \nSets value for random seed to produce similar result in each run.","metadata":{"papermill":{"duration":0.013107,"end_time":"2024-04-04T17:26:31.662869","exception":false,"start_time":"2024-04-04T17:26:31.649762","status":"completed"},"tags":[]}},{"cell_type":"code","source":"keras.utils.set_random_seed(CFG.seed)","metadata":{"papermill":{"duration":0.021262,"end_time":"2024-04-04T17:26:31.697346","exception":false,"start_time":"2024-04-04T17:26:31.676084","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:18.499257Z","iopub.execute_input":"2024-04-21T03:44:18.499541Z","iopub.status.idle":"2024-04-21T03:44:18.509172Z","shell.execute_reply.started":"2024-04-21T03:44:18.499517Z","shell.execute_reply":"2024-04-21T03:44:18.508281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üßÆ | Mixed Precision","metadata":{}},{"cell_type":"code","source":"keras.mixed_precision.set_global_policy(\"mixed_float16\")","metadata":{"execution":{"iopub.status.busy":"2024-04-21T03:44:18.512244Z","iopub.execute_input":"2024-04-21T03:44:18.512801Z","iopub.status.idle":"2024-04-21T03:44:18.520163Z","shell.execute_reply.started":"2024-04-21T03:44:18.512773Z","shell.execute_reply":"2024-04-21T03:44:18.519304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìÅ | Dataset Path ","metadata":{"papermill":{"duration":0.013484,"end_time":"2024-04-04T17:26:31.724167","exception":false,"start_time":"2024-04-04T17:26:31.710683","status":"completed"},"tags":[]}},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/learning-agency-lab-automated-essay-scoring-2'","metadata":{"papermill":{"duration":0.020699,"end_time":"2024-04-04T17:26:31.758153","exception":false,"start_time":"2024-04-04T17:26:31.737454","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:18.521193Z","iopub.execute_input":"2024-04-21T03:44:18.521487Z","iopub.status.idle":"2024-04-21T03:44:18.531163Z","shell.execute_reply.started":"2024-04-21T03:44:18.521464Z","shell.execute_reply":"2024-04-21T03:44:18.530139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìñ | Meta Data\n\n**Files in the dataset:**\n\n- `{test|train}.csv`\n  - `essay_id`: Unique identifier for each essay.\n  - `full_text`: Essay text.\n  - `score`: Essay's score from `1-6`.\n- `sample_submission.csv`: Valid sample submission.\n\n**What does the `score` mean?**\n\nThe `score` represents the quality of student-written argumentative essays. Essays were rated based on a rubric covering perspective development, critical thinking, evidence use, organization, language, and grammar/mechanics. Here's a summary of the scoring criteria:\n\n| Score | Description |\n|-------|-------------|\n| 6     | Clear mastery with few errors, outstanding critical thinking, appropriate evidence, well-organized, skilled language use. |\n| 5     | Reasonable mastery with occasional errors, strong critical thinking, generally appropriate evidence, well-organized, good language use. |\n| 4     | Adequate mastery with some lapses, competent critical thinking, adequate evidence, generally organized, fair language use. |\n| 3     | Developing mastery with weaknesses, limited critical thinking, inconsistent evidence, limited organization, fair language use with weaknesses. |\n| 2     | Little mastery with serious flaws, weak critical thinking, insufficient evidence, poor organization, limited language use with frequent errors. |\n| 1     | Very little or no mastery, severely flawed, no viable point of view, disorganized, fundamental language flaws, pervasive grammar/mechanics errors. |\n\n> This grading is very similar to the grading used in the [ETS GRE (Graduate Record Examinations) AWA](https://www.ets.org/gre/test-takers/general-test/prepare/content/analytical-writing.html) exam, where prospective graduate students are asked to write essays to judge their analytical abilities, and their scores are later used for graduate admission. \n","metadata":{"papermill":{"duration":0.013251,"end_time":"2024-04-04T17:26:31.78481","exception":false,"start_time":"2024-04-04T17:26:31.771559","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Load data\ndf = pd.read_csv(f'{BASE_PATH}/train.csv')  # Read CSV file into a DataFrame\n\n# Display information about the train data\nprint(\"# Train Data: {:,}\".format(len(df)))\nprint(\"# Sample:\")\ndisplay(df.head(2))","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.777957,"end_time":"2024-04-04T17:26:32.576028","exception":false,"start_time":"2024-04-04T17:26:31.798071","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:18.532358Z","iopub.execute_input":"2024-04-21T03:44:18.53266Z","iopub.status.idle":"2024-04-21T03:44:19.323305Z","shell.execute_reply.started":"2024-04-21T03:44:18.532637Z","shell.execute_reply":"2024-04-21T03:44:19.322383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üî™ | Data Split\n\nIn the code snippet provided below, we will divide the existing **train** data into folds using a stratification of `label` column.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split  # Import package\n\ntrain_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"score\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T03:44:19.324399Z","iopub.execute_input":"2024-04-21T03:44:19.324654Z","iopub.status.idle":"2024-04-21T03:44:20.259196Z","shell.execute_reply.started":"2024-04-21T03:44:19.324632Z","shell.execute_reply":"2024-04-21T03:44:20.258403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üßÇ | Process Labels for Ordinal Regression\n\n**What is Ordinal Regression?**\nOrdinal regression is a type of supervised learning algorithm used to predict an ordinal or ranked dependent variable. Unlike in typical classification problems where the target variable is categorical, in ordinal regression the target variable has a ordering or ranking. It is also different from typical regression, where the target variable is continuous. In ordinal regression, the target variable has a discrete, ordered set of values, such as levels of satisfaction or performance grades.\n\n**Why do we need it?**\nOrdinal regression is useful when the target variable (in our competition, the `score` of an essay) represents a ranking or order. Specifically, ordinal regression can capture the inherent order in the target variable, which standard classification models may not be able to do effectively.\n\nFor Ordinal Regression, we have to transform the labels, which is different from typical classification or regression. The following code will convert essay scores to an ordinal matrix, which will be used as the ground truth for calculating the loss.","metadata":{"papermill":{"duration":0.013275,"end_time":"2024-04-04T17:26:32.602911","exception":false,"start_time":"2024-04-04T17:26:32.589636","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def to_ordinal(y, num_classes=None, dtype=\"float32\"):\n    \"\"\"Converts a class vector (integers) to an ordinal regression matrix.\n\n    This utility encodes class vector to ordinal regression/classification\n    matrix where each sample is indicated by a row and rank of that sample is\n    indicated by number of ones in that row.\n\n    Args:\n        y: Array-like with class values to be converted into a matrix\n            (integers from 0 to `num_classes - 1`).\n        num_classes: Total number of classes. If `None`, this would be inferred\n            as `max(y) + 1`.\n        dtype: The data type expected by the input. Default: `'float32'`.\n\n    Returns:\n        An ordinal regression matrix representation of the input as a NumPy\n        array. The class axis is placed last.\n    \"\"\"\n    y = np.array(y, dtype=\"int\")\n    input_shape = y.shape\n\n    # Shrink the last dimension if the shape is (..., 1).\n    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n        input_shape = tuple(input_shape[:-1])\n\n    y = y.reshape(-1)\n    if not num_classes:\n        num_classes = np.max(y) + 1\n    n = y.shape[0]\n    range_values = np.arange(num_classes - 1)\n    range_values = np.tile(np.expand_dims(range_values, 0), [n, 1])\n    ordinal = np.zeros((n, num_classes - 1), dtype=dtype)\n    ordinal[range_values < np.expand_dims(y, -1)] = 1\n    output_shape = input_shape + (num_classes - 1,)\n    ordinal = np.reshape(ordinal, output_shape)\n    return ordinal","metadata":{"papermill":{"duration":0.027941,"end_time":"2024-04-04T17:26:32.644064","exception":false,"start_time":"2024-04-04T17:26:32.616123","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:20.260293Z","iopub.execute_input":"2024-04-21T03:44:20.260829Z","iopub.status.idle":"2024-04-21T03:44:20.269641Z","shell.execute_reply.started":"2024-04-21T03:44:20.260803Z","shell.execute_reply":"2024-04-21T03:44:20.268716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [1, 3, 5, 2, 6]\n\nto_ordinal(scores)","metadata":{"papermill":{"duration":0.024096,"end_time":"2024-04-04T17:26:32.68166","exception":false,"start_time":"2024-04-04T17:26:32.657564","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:20.270745Z","iopub.execute_input":"2024-04-21T03:44:20.271Z","iopub.status.idle":"2024-04-21T03:44:20.285903Z","shell.execute_reply.started":"2024-04-21T03:44:20.270976Z","shell.execute_reply":"2024-04-21T03:44:20.284989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Conversion","metadata":{}},{"cell_type":"code","source":"train_df[\"label\"] = to_ordinal(train_df.score.values).tolist()\nvalid_df[\"label\"] = to_ordinal(valid_df.score.values).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T03:44:20.287081Z","iopub.execute_input":"2024-04-21T03:44:20.287569Z","iopub.status.idle":"2024-04-21T03:44:20.308347Z","shell.execute_reply.started":"2024-04-21T03:44:20.287538Z","shell.execute_reply":"2024-04-21T03:44:20.30769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üé® | EDA","metadata":{"papermill":{"duration":0.013731,"end_time":"2024-04-04T17:26:32.744069","exception":false,"start_time":"2024-04-04T17:26:32.730338","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Show distribution of answers using a bar plot\nplt.figure(figsize=(8, 4))\ndf.score.value_counts().plot.bar(color=[cmap(0.0), cmap(0.25), cmap(0.65), cmap(0.9), cmap(1.0)])\nplt.xlabel(\"Score\")\nplt.ylabel(\"Count\")\nplt.title(\"Score distribution for Train Data\")\nplt.show()\n\n# Show distribution of essay length using a bar plot\nplt.figure(figsize=(8, 4))\ndf['essay_length'] = df.full_text.map(len)\ndf.essay_length.plot.hist(logy=False, color=cmap(0.9))\nplt.xlabel(\"Essay Length\")\nplt.ylabel(\"Count\")\nplt.title(\"Essay Length distribution for Train Data\")\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.021843,"end_time":"2024-04-04T17:26:32.779688","exception":false,"start_time":"2024-04-04T17:26:32.757845","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:20.309337Z","iopub.execute_input":"2024-04-21T03:44:20.309613Z","iopub.status.idle":"2024-04-21T03:44:20.910291Z","shell.execute_reply.started":"2024-04-21T03:44:20.30959Z","shell.execute_reply":"2024-04-21T03:44:20.909394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üçΩÔ∏è | Preprocessing\n\n**What it does:** The preprocessor takes input strings and transforms them into a dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs.\n\n**Why it's important:** Initially, raw text data is complex and challenging for modeling due to its high dimensionality. By converting text into a compact set of tokens, such as transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`, we simplify the data. Many models rely on special tokens and additional tensors to understand input. These tokens help divide input and identify padding, among other tasks. Making all sequences the same length through padding boosts computational efficiency, making subsequent steps smoother.\n\nExplore the following pages to access the available preprocessing and tokenizer layers in **KerasNLP**:\n- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)","metadata":{"papermill":{"duration":0.01354,"end_time":"2024-04-04T17:26:33.970237","exception":false,"start_time":"2024-04-04T17:26:33.956697","status":"completed"},"tags":[]}},{"cell_type":"code","source":"preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n    preset=CFG.preset, # Name of the model\n    sequence_length=CFG.sequence_length, # Max sequence length, will be padded if shorter\n)","metadata":{"papermill":{"duration":2.92789,"end_time":"2024-04-04T17:26:36.91194","exception":false,"start_time":"2024-04-04T17:26:33.98405","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:20.911499Z","iopub.execute_input":"2024-04-21T03:44:20.911765Z","iopub.status.idle":"2024-04-21T03:44:23.28017Z","shell.execute_reply.started":"2024-04-21T03:44:20.911741Z","shell.execute_reply":"2024-04-21T03:44:23.279158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let's examine what the output shape of the preprocessing layer looks like. The output shape of the layer can be represented as $(num\\_choices, sequence\\_length)$.","metadata":{"papermill":{"duration":0.014291,"end_time":"2024-04-04T17:26:36.940792","exception":false,"start_time":"2024-04-04T17:26:36.926501","status":"completed"},"tags":[]}},{"cell_type":"code","source":"inp = preprocessor(df.full_text.iloc[0])  # Process text for the first row\n\n# Display the shape of each processed output\nfor k, v in inp.items():\n    print(k, \":\", v.shape)","metadata":{"papermill":{"duration":1.330109,"end_time":"2024-04-04T17:26:38.284933","exception":false,"start_time":"2024-04-04T17:26:36.954824","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:23.284744Z","iopub.execute_input":"2024-04-21T03:44:23.285037Z","iopub.status.idle":"2024-04-21T03:44:24.462371Z","shell.execute_reply.started":"2024-04-21T03:44:23.285013Z","shell.execute_reply":"2024-04-21T03:44:24.461446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll use the `preprocessing_fn` function to transform each text option using the `dataset.map(preprocessing_fn)` method.","metadata":{"papermill":{"duration":0.014059,"end_time":"2024-04-04T17:26:38.313541","exception":false,"start_time":"2024-04-04T17:26:38.299482","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def preprocess_fn(text, label=None):\n    text = preprocessor(text)  # Preprocess text\n    return (text, label) if label is not None else text  # Return processed text and label if available","metadata":{"papermill":{"duration":0.023247,"end_time":"2024-04-04T17:26:38.351516","exception":false,"start_time":"2024-04-04T17:26:38.328269","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:24.463553Z","iopub.execute_input":"2024-04-21T03:44:24.463845Z","iopub.status.idle":"2024-04-21T03:44:24.470282Z","shell.execute_reply.started":"2024-04-21T03:44:24.463819Z","shell.execute_reply":"2024-04-21T03:44:24.469523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üçö | DataLoader\n\nThe code below sets up a robust data flow pipeline using `tf.data.Dataset` for data processing. Notable aspects of `tf.data` include its ability to simplify pipeline construction and represent components in sequences.\n\nTo learn more about `tf.data`, refer to this [documentation](https://www.tensorflow.org/guide/data).","metadata":{"papermill":{"duration":0.013798,"end_time":"2024-04-04T17:26:38.379574","exception":false,"start_time":"2024-04-04T17:26:38.365776","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def build_dataset(texts, labels=None, batch_size=32,\n                  cache=True, drop_remainder=True,\n                  shuffle=1024):\n    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n    slices = (texts,) if labels is None else (texts, labels)  # Create slices\n    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n    opt = tf.data.Options()  # Create dataset options\n    if shuffle: \n        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n        opt.experimental_deterministic = False\n    ds = ds.with_options(opt)  # Set dataset options\n    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n    ds = ds.prefetch(AUTO)  # Prefetch next batch\n    return ds","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.025502,"end_time":"2024-04-04T17:26:38.419525","exception":false,"start_time":"2024-04-04T17:26:38.394023","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:24.471315Z","iopub.execute_input":"2024-04-21T03:44:24.471669Z","iopub.status.idle":"2024-04-21T03:44:24.480617Z","shell.execute_reply.started":"2024-04-21T03:44:24.471645Z","shell.execute_reply":"2024-04-21T03:44:24.479632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Train/Valid Dataset\n\nThe function below generates the training and validation datasets.","metadata":{"papermill":{"duration":0.014031,"end_time":"2024-04-04T17:26:38.448005","exception":false,"start_time":"2024-04-04T17:26:38.433974","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Train Data\ntrain_texts = train_df.full_text.tolist()  # Extract training texts\ntrain_labels = np.array(train_df.label.tolist())  # Extract training labels\n\n# Build training dataset\ntrain_ds = build_dataset(\n    train_texts, train_labels, batch_size=CFG.batch_size, shuffle=True\n)\n\n# Valid Data\nvalid_texts = valid_df.full_text.tolist()  # Extract validation texts\nvalid_labels = np.array(valid_df.label.tolist())  # Extract validation labels\n\n# Build validation dataset\nvalid_ds = build_dataset(\n    valid_texts, valid_labels, batch_size=CFG.batch_size, shuffle=False\n)\n","metadata":{"_kg_hide-input":false,"papermill":{"duration":2.920922,"end_time":"2024-04-04T17:26:41.38299","exception":false,"start_time":"2024-04-04T17:26:38.462068","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:24.48175Z","iopub.execute_input":"2024-04-21T03:44:24.482008Z","iopub.status.idle":"2024-04-21T03:44:27.638109Z","shell.execute_reply.started":"2024-04-21T03:44:24.481986Z","shell.execute_reply":"2024-04-21T03:44:27.637308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ‚öì | LR Schedule\n\nImplementing a learning rate scheduler is crucial for transfer learning. The learning rate initiates at `lr_start` and gradually tapers down to `lr_min` using various techniques, including:\n- `step`: Lowering the learning rate in step-wise manner resembling stairs.\n- `cos`: Utilizing a cosine curve to gradually reduce the learning rate.\n- `exp`: Exponentially decreasing the learning rate.\n\n**Importance:** A well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation.","metadata":{"papermill":{"duration":0.014164,"end_time":"2024-04-04T17:26:41.413942","exception":false,"start_time":"2024-04-04T17:26:41.399778","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import math\n\ndef get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n    lr_start, lr_max, lr_min = 0.6e-5, 0.3e-5 * batch_size, 0.3e-5\n    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.75\n\n    def lrfn(epoch):  # Learning rate update function\n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        return lr\n\n    if plot:  # Plot lr curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('lr')\n        plt.title('LR Scheduler')\n        plt.show()\n\n    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.028237,"end_time":"2024-04-04T17:26:41.45643","exception":false,"start_time":"2024-04-04T17:26:41.428193","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:27.639252Z","iopub.execute_input":"2024-04-21T03:44:27.63955Z","iopub.status.idle":"2024-04-21T03:44:27.649288Z","shell.execute_reply.started":"2024-04-21T03:44:27.639522Z","shell.execute_reply":"2024-04-21T03:44:27.648365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_cb = get_lr_callback(CFG.batch_size, plot=True)","metadata":{"papermill":{"duration":0.337701,"end_time":"2024-04-04T17:26:41.808474","exception":false,"start_time":"2024-04-04T17:26:41.470773","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:27.650473Z","iopub.execute_input":"2024-04-21T03:44:27.650799Z","iopub.status.idle":"2024-04-21T03:44:27.934738Z","shell.execute_reply.started":"2024-04-21T03:44:27.650768Z","shell.execute_reply":"2024-04-21T03:44:27.93393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üíæ | Model Checkpointing\n\nThe following code will create a callback that will save the best checkpoint of the model during training, which we will use for inference in the submission.","metadata":{}},{"cell_type":"code","source":"ckpt_cb = keras.callbacks.ModelCheckpoint(\n    \"best_model.weights.h5\",\n    monitor=\"val_weighted_kappa\",\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"max\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T03:44:27.935875Z","iopub.execute_input":"2024-04-21T03:44:27.936142Z","iopub.status.idle":"2024-04-21T03:44:27.940556Z","shell.execute_reply.started":"2024-04-21T03:44:27.936118Z","shell.execute_reply":"2024-04-21T03:44:27.939602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìè | Metric\n\nThe metric for this competition is quadratic **Weighted Kappa**. This metric is particularly useful for tasks involving ordinal classification (where labels have inherent order). The following code implements this metric from scratch. This metric is implemented taking inspiration from [this TensorFlow implementation](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/WeightedKappaLoss). You can learn more about this metric [here](https://www.sciencedirect.com/science/article/abs/pii/S0167865517301666).","metadata":{}},{"cell_type":"code","source":"class WeightedKappa(keras.metrics.Metric):\n    def __init__(self, num_classes=6, epsilon=1e-6):\n        super().__init__(name=\"weighted_kappa\")\n        self.num_classes = num_classes\n        self.epsilon = epsilon\n\n        label_vec = keras.ops.arange(num_classes, dtype=keras.backend.floatx())\n        self.row_label_vec = keras.ops.reshape(label_vec, [1, num_classes])\n        self.col_label_vec = keras.ops.reshape(label_vec, [num_classes, 1])\n        col_mat = keras.ops.tile(self.col_label_vec, [1, num_classes])\n        row_mat = keras.ops.tile(self.row_label_vec, [num_classes, 1])\n        self.weight_mat = (col_mat - row_mat) ** 2\n\n        self.numerator = self.add_weight(name=\"numerator\", initializer=\"zeros\")\n        self.denominator = self.add_weight(name=\"denominator\", initializer=\"zeros\")\n\n    def update_state(self, y_true, y_pred, **args):\n        # revert ordinal regression labels to classification labels\n        y_true = keras.ops.one_hot(keras.ops.sum(y_true, axis=-1) - 1, 6)\n        y_pred = keras.ops.one_hot(\n            keras.ops.sum(keras.ops.cast(y_pred > 0.5, dtype=\"int8\"), axis=-1) - 1, 6\n        )\n        # weighted kappa calculation\n        y_true = keras.ops.cast(y_true, dtype=self.col_label_vec.dtype)\n        y_pred = keras.ops.cast(y_pred, dtype=self.weight_mat.dtype)\n        batch_size = keras.ops.shape(y_true)[0]\n\n        cat_labels = keras.ops.matmul(y_true, self.col_label_vec)\n        cat_label_mat = keras.ops.tile(cat_labels, [1, self.num_classes])\n        row_label_mat = keras.ops.tile(self.row_label_vec, [batch_size, 1])\n\n        weight = (cat_label_mat - row_label_mat) ** 2\n\n        self.numerator.assign_add(keras.ops.sum(weight * y_pred))\n        label_dist = keras.ops.sum(y_true, axis=0, keepdims=True)\n        pred_dist = keras.ops.sum(y_pred, axis=0, keepdims=True)\n        w_pred_dist = keras.ops.matmul(\n            self.weight_mat, keras.ops.transpose(pred_dist, [1, 0])\n        )\n        self.denominator.assign_add(\n            keras.ops.sum(keras.ops.matmul(label_dist, w_pred_dist))\n        )\n\n    def result(self):\n        return 1.0 - keras.ops.divide_no_nan(self.numerator, self.denominator)\n\n    def reset_state(self):\n        self.numerator.assign(0)\n        self.denominator.assign(0)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T03:44:27.941946Z","iopub.execute_input":"2024-04-21T03:44:27.942496Z","iopub.status.idle":"2024-04-21T03:44:27.95851Z","shell.execute_reply.started":"2024-04-21T03:44:27.942465Z","shell.execute_reply":"2024-04-21T03:44:27.95762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ü§ñ | Modeling\n\n","metadata":{"papermill":{"duration":0.014695,"end_time":"2024-04-04T17:26:41.838088","exception":false,"start_time":"2024-04-04T17:26:41.823393","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## KerasNLP Classifier\n\nThe `KerasNLP` library provides comprehensive, ready-to-use implementations of popular NLP model architectures. It features a variety of pre-trained models including `Bert`, `Roberta`, `DebertaV3`, and more. In this notebook, we'll showcase the usage of `DebertaV3`. However, feel free to explore all available models in the [KerasNLP documentation](https://keras.io/api/keras_nlp/models/). Also, for a deeper understanding of `KerasNLP`, refer to the informative [getting started guide](https://keras.io/guides/keras_nlp/getting_started/).\n\nOur approach involves using `keras_nlp.models.XXClassifier` to process each text and generate logits. These logits are passed through a `sigmoid` function to produce the final output.\n\n> Note that we are tackling this problem as an **ordinal regression** problem, thus we have used `sigmoid` activation, but we can also consider this problem as a classification problem; then, we would've used `num_classes=6`, `softmax` activation, and `categorical_crossentropy` loss. We could even consider this as a **regression** problem with `num_classes=1`, `no activation` layer, and regression losses like MSE, MAE, etc. You are welcome to experiment with the typical classification and regression methods.","metadata":{"papermill":{"duration":0.014862,"end_time":"2024-04-04T17:26:41.867647","exception":false,"start_time":"2024-04-04T17:26:41.852785","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create a DebertaV3Classifier model\nclassifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n    CFG.preset, preprocessor=None, num_classes=6\n)\ninputs = classifier.input\nlogits = classifier(inputs)\n\n# Compute final output\noutputs = keras.layers.Activation(\"sigmoid\")(logits)\n\n# Build Model\nmodel = keras.Model(inputs, outputs)\n\n# Compile the model with optimizer, loss, and metrics\nmodel.compile(\n    optimizer=keras.optimizers.Adam(5e-6),\n    loss=keras.losses.BinaryCrossentropy(),\n    metrics=[\n        WeightedKappa()\n    ],\n)\nmodel.summary()\n","metadata":{"papermill":{"duration":0.025253,"end_time":"2024-04-04T17:26:41.908072","exception":false,"start_time":"2024-04-04T17:26:41.882819","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:27.959727Z","iopub.execute_input":"2024-04-21T03:44:27.960814Z","iopub.status.idle":"2024-04-21T03:44:36.327229Z","shell.execute_reply.started":"2024-04-21T03:44:27.960778Z","shell.execute_reply":"2024-04-21T03:44:36.326379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üöÇ | Training\n\nFollowing code will train the model on the training dataset and evaluate on the validation dataset.","metadata":{"papermill":{"duration":0.014704,"end_time":"2024-04-04T17:26:51.093188","exception":false,"start_time":"2024-04-04T17:26:51.078484","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Start training the model\nhistory = model.fit(\n    train_ds,\n    epochs=CFG.epochs,\n    validation_data=valid_ds,\n    callbacks=[lr_cb, ckpt_cb]\n)","metadata":{"_kg_hide-input":true,"papermill":{"duration":97.399391,"end_time":"2024-04-04T17:28:28.508119","exception":false,"start_time":"2024-04-04T17:26:51.108728","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-21T03:44:36.328261Z","iopub.execute_input":"2024-04-21T03:44:36.328552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Result Summary","metadata":{"papermill":{"duration":0.060814,"end_time":"2024-04-04T17:28:28.630539","exception":false,"start_time":"2024-04-04T17:28:28.569725","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Find the epoch with the best validation accuracy\nbest_epoch = np.argmax(model.history.history['val_weighted_kappa'])\nbest_score = model.history.history['val_weighted_kappa'][best_epoch]\nbest_loss = model.history.history['val_loss'][best_epoch]\n\n# Print and display best results\nprint(f'\\n{\"=\" * 17} RESULTS {\"=\" * 17}')\nprint(f'>>>> BEST Loss  : {best_loss:.3f}\\n>>>> BEST Score : {best_score:.3f}\\n>>>> BEST Epoch : {best_epoch}')\nprint('=' * 50)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.072931,"end_time":"2024-04-04T17:28:28.76968","exception":false,"start_time":"2024-04-04T17:28:28.696749","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üß™ | Testing\n\nIn this section, we will visually test how our model performs on some samples from the validation data.\n\n> Note that we are converting the ordinal regression model outputs with `sum`, unlike a typical classification problem where we would use `argmax`.","metadata":{"papermill":{"duration":0.063314,"end_time":"2024-04-04T17:28:28.893965","exception":false,"start_time":"2024-04-04T17:28:28.830651","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Load best checkpoint\nmodel.load_weights(\"best_model.weights.h5\")\n\n# Make predictions using the trained model on last validation data\nvalid_preds = model.predict(valid_ds, verbose=0)\n\n# Format predictions and true answers\npred_scores = np.sum((valid_preds > 0.5).astype(int), axis=-1)\ntrue_scores = valid_df.score.values\n\n# Check 5 Predictions\nprint(\"# Predictions\\n\")\nfor i in range(5):\n    row = valid_df.iloc[i]\n    text = row.full_text\n    pred_answer = pred_scores[i]\n    true_answer = true_scores[i]\n    print(f\"‚ùì Text {i+1}:\\n{text[:150]} .... {text[-150:]}\\n\")\n    print(f\"‚úÖ True: {true_answer}\\n\")\n    print(f\"ü§ñ Predicted: {pred_answer}\\n\")\n    print(\"-\" * 90, \"\\n\")\n","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.070797,"end_time":"2024-04-04T17:28:29.158389","exception":false,"start_time":"2024-04-04T17:28:29.087592","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üì¨ | Submission\n\nIn this section, we will infer our model on the test data and then finally prepare the submission file.","metadata":{"papermill":{"duration":0.062078,"end_time":"2024-04-04T17:28:29.283571","exception":false,"start_time":"2024-04-04T17:28:29.221493","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Build Test Dataset","metadata":{"papermill":{"duration":0.06084,"end_time":"2024-04-04T17:28:29.407049","exception":false,"start_time":"2024-04-04T17:28:29.346209","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# # Train Data\ntest_df = pd.read_csv(f\"{BASE_PATH}/test.csv\")\ntest_texts = test_df.full_text.fillna(\"\").tolist()  # Extract training texts\n\n# Build training dataset\ntest_ds = build_dataset(\n    test_texts,\n    labels=None,\n    batch_size=min(CFG.batch_size, len(test_df)),\n    shuffle=False,\n    drop_remainder=False,  # include all samples\n)\n","metadata":{"papermill":{"duration":0.512605,"end_time":"2024-04-04T17:28:29.98127","exception":false,"start_time":"2024-04-04T17:28:29.468665","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference on Test Data","metadata":{"papermill":{"duration":0.060691,"end_time":"2024-04-04T17:28:30.103013","exception":false,"start_time":"2024-04-04T17:28:30.042322","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Do inference\ntest_preds = model.predict(test_ds, verbose=1)\n\n# Convert probabilities to class labels\ntest_preds = np.sum((test_preds>0.5).astype(int), axis=-1).clip(1, 6)","metadata":{"papermill":{"duration":4.952443,"end_time":"2024-04-04T17:28:35.116397","exception":false,"start_time":"2024-04-04T17:28:30.163954","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission File","metadata":{"papermill":{"duration":0.060982,"end_time":"2024-04-04T17:28:35.2392","exception":false,"start_time":"2024-04-04T17:28:35.178218","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create a DataFrame to store the submission\nsub_df = test_df[[\"essay_id\"]].copy()\n\n# Add the formatted predictions to the submission DataFrame\nsub_df[\"score\"] = test_preds\n\n# Save Submission\nsub_df.to_csv('submission.csv',index=False)\n\n# Display the first 2 rows of the submission DataFrame\nsub_df.head()","metadata":{"papermill":{"duration":0.080626,"end_time":"2024-04-04T17:28:35.511049","exception":false,"start_time":"2024-04-04T17:28:35.430423","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ‚úçÔ∏è | Reference\n* [LLM Science Exam: KerasCore + KerasNLP [TPU]](https://www.kaggle.com/code/awsaf49/llm-science-exam-kerascore-kerasnlp-tpu)\n* [Keras NLP](https://keras.io/api/keras_nlp/)\n* [Triple Stratified KFold with TFRecords](https://www.kaggle.com/code/cdeotte/triple-stratified-kfold-with-tfrecords) by @cdeotte","metadata":{"papermill":{"duration":0.060667,"end_time":"2024-04-04T17:28:35.633612","exception":false,"start_time":"2024-04-04T17:28:35.572945","status":"completed"},"tags":[]}}]}